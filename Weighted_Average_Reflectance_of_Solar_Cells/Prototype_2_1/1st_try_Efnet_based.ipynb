{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EffecientNet Finetuned Model\n",
    "\n",
    "- 모델 앞단에는 Efficient pretrained model을 사용(Imagenet Based)\n",
    "- 뒷단에 Fully Connected Layer (NN) 연결\n",
    "- Effnet 뒷부분과 추가연결된 FC Layer만 Finetuning 진행.\n",
    "- 성능 매우 좋지 않았음. 너무 필요없는 정보가 많은 것으로 보여짐\n",
    "- MSE 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('data/test_img')) # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thickness = pd.read_csv('./data/Thickness.csv')\n",
    "Thickness = Thickness.drop([33]) # 9-1 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>84.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>98.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>97.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>96.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>97.766667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Thickness\n",
       "0    48.266667\n",
       "1    47.966667\n",
       "2    48.166667\n",
       "3    48.600000\n",
       "4    59.533333\n",
       "..         ...\n",
       "122  84.633333\n",
       "123  98.366667\n",
       "124  97.033333\n",
       "125  96.266667\n",
       "126  97.766667\n",
       "\n",
       "[127 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Thickness.reset_index(drop=True, inplace=True)\n",
    "Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/test_img/AI-1_01_transformed.jpg',\n",
       " './data/test_img/AI-1_02_transformed.jpg',\n",
       " './data/test_img/AI-1_03_transformed.jpg',\n",
       " './data/test_img/AI-1_04_transformed.jpg',\n",
       " './data/test_img/AI-2_01_transformed.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list = []\n",
    "\n",
    "for i in range(1, 33):\n",
    "    for j in range(1, 5):\n",
    "        if i == 9 and j == 1: \n",
    "            continue\n",
    "        img_path_list.append('./data/test_img/AI-{}_0{}_transformed.jpg'.format(i, j))\n",
    "        \n",
    "img_path_list[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, img_path, thickness, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.thickness = thickness\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.img_path[idx])\n",
    "        img = np.array(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        y = self.thickness[idx]\n",
    "        return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "train, test = train_test_split(img_path_list, test_size=0.2, random_state=seed)\n",
    "\n",
    "train_dataset = dataset(train, Thickness['Thickness'], transform)\n",
    "test_dataset = dataset(test, Thickness['Thickness'], transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 26\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\se99a/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "efficientnet = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.efficientnet = efficientnet\n",
    "        self.fc1 = nn.Linear(1000, 1)\n",
    "        \n",
    "        for param in self.efficientnet.parameters():\n",
    "            if param.dim() == 4:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (efficientnet): GenEfficientNet(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): SiLU(inplace=True)\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): SiLU(inplace=True)\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return model\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    output_list  = []\n",
    "    thickness_list = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            thickness_list.append(target)\n",
    "            data = data.to(device)\n",
    "            target = target.float().to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target.unsqueeze(1)).item()\n",
    "            output_list.append(output)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, output_list, thickness_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/101 (0%)]\tLoss: 7094.571289\n",
      "Train Epoch: 1 [0/101 (0%)]\tLoss: 5582.678223\n",
      "Train Epoch: 2 [0/101 (0%)]\tLoss: 5260.939453\n",
      "Train Epoch: 3 [0/101 (0%)]\tLoss: 3880.814209\n",
      "Train Epoch: 4 [0/101 (0%)]\tLoss: 3739.570557\n",
      "Train Epoch: 5 [0/101 (0%)]\tLoss: 4374.734375\n",
      "Train Epoch: 6 [0/101 (0%)]\tLoss: 3186.885010\n",
      "Train Epoch: 7 [0/101 (0%)]\tLoss: 2295.227783\n",
      "Train Epoch: 8 [0/101 (0%)]\tLoss: 2216.623047\n",
      "Train Epoch: 9 [0/101 (0%)]\tLoss: 1583.897217\n",
      "Train Epoch: 10 [0/101 (0%)]\tLoss: 1023.884155\n",
      "Train Epoch: 11 [0/101 (0%)]\tLoss: 1196.077148\n",
      "Train Epoch: 12 [0/101 (0%)]\tLoss: 651.279541\n",
      "Train Epoch: 13 [0/101 (0%)]\tLoss: 605.916992\n",
      "Train Epoch: 14 [0/101 (0%)]\tLoss: 670.305237\n",
      "Train Epoch: 15 [0/101 (0%)]\tLoss: 260.035675\n",
      "Train Epoch: 16 [0/101 (0%)]\tLoss: 188.294678\n",
      "Train Epoch: 17 [0/101 (0%)]\tLoss: 258.544861\n",
      "Train Epoch: 18 [0/101 (0%)]\tLoss: 146.365356\n",
      "Train Epoch: 19 [0/101 (0%)]\tLoss: 221.060272\n",
      "Train Epoch: 20 [0/101 (0%)]\tLoss: 18.536547\n",
      "Train Epoch: 21 [0/101 (0%)]\tLoss: 57.559982\n",
      "Train Epoch: 22 [0/101 (0%)]\tLoss: 80.768486\n",
      "Train Epoch: 23 [0/101 (0%)]\tLoss: 13.532734\n",
      "Train Epoch: 24 [0/101 (0%)]\tLoss: 139.962158\n",
      "Train Epoch: 25 [0/101 (0%)]\tLoss: 60.571404\n",
      "Train Epoch: 26 [0/101 (0%)]\tLoss: 52.195343\n",
      "Train Epoch: 27 [0/101 (0%)]\tLoss: 23.173025\n",
      "Train Epoch: 28 [0/101 (0%)]\tLoss: 13.016096\n",
      "Train Epoch: 29 [0/101 (0%)]\tLoss: 37.453693\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "model = train(model, train_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, output_list, thickness_list = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.62700711763822"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.array(output_list[0])\n",
    "thickness = np.array(thickness_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output, 'o')\n",
    "plt.plot(thickness, 'x')\n",
    "plt.legend(['prediction', 'actual_thickness'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.175697</td>\n",
       "      <td>48.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.086914</td>\n",
       "      <td>81.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.280045</td>\n",
       "      <td>93.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.633202</td>\n",
       "      <td>68.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.485489</td>\n",
       "      <td>81.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>87.106194</td>\n",
       "      <td>68.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102.748230</td>\n",
       "      <td>59.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>89.790176</td>\n",
       "      <td>92.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.198845</td>\n",
       "      <td>93.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92.428589</td>\n",
       "      <td>59.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>85.651855</td>\n",
       "      <td>69.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84.669777</td>\n",
       "      <td>81.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93.586700</td>\n",
       "      <td>79.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104.570686</td>\n",
       "      <td>60.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>98.594826</td>\n",
       "      <td>75.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>93.855469</td>\n",
       "      <td>47.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>98.850380</td>\n",
       "      <td>48.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>82.534592</td>\n",
       "      <td>74.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>92.873657</td>\n",
       "      <td>80.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>96.131889</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>91.745483</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.169128</td>\n",
       "      <td>48.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>81.708534</td>\n",
       "      <td>68.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>88.225616</td>\n",
       "      <td>80.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>88.405609</td>\n",
       "      <td>92.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>87.263000</td>\n",
       "      <td>81.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction  thickness\n",
       "0    84.175697  48.166667\n",
       "1    94.086914  81.466667\n",
       "2    91.280045  93.500000\n",
       "3    95.633202  68.266667\n",
       "4   102.485489  81.833333\n",
       "5    87.106194  68.833333\n",
       "6   102.748230  59.766667\n",
       "7    89.790176  92.400000\n",
       "8   100.198845  93.533333\n",
       "9    92.428589  59.533333\n",
       "10   85.651855  69.700000\n",
       "11   84.669777  81.733333\n",
       "12   93.586700  79.100000\n",
       "13  104.570686  60.100000\n",
       "14   98.594826  75.033333\n",
       "15   93.855469  47.966667\n",
       "16   98.850380  48.266667\n",
       "17   82.534592  74.766667\n",
       "18   92.873657  80.033333\n",
       "19   96.131889  79.000000\n",
       "20   91.745483  59.800000\n",
       "21   83.169128  48.600000\n",
       "22   81.708534  68.200000\n",
       "23   88.225616  80.666667\n",
       "24   88.405609  92.833333\n",
       "25   87.263000  81.500000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'prediction': output.reshape(-1), 'thickness': thickness.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "640.3021871322825"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/1st_pred_real.csv\")\n",
    "# MSE\n",
    "print(\"MSE::\")\n",
    "np.mean((df['prediction'] - df['thickness'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
